\section{Introduction}\label{Introduction}

Traditionally, the capable of a general purpose language can be extended to special domain by creating an embedded DSL (Domain-Specific Language). For example, Akka provides a DSL to create finite-state machines \cite{lightbend2017akka}, which consists of some domain-specific operators including \lstinline{when}, \lstinline{goto}, \lstinline{stay}, etc. Although those operators looks similar to native control flow, they are not able to be embedded in native \lstinline{if}, \lstinline{while} or \lstinline{try} blocks, because Akka's DSL split code into small closures, preventing ordinary control flows from crossing the boundary of those closures. TensorFlow's control flow operations \cite{abadi2016tensorflow} and Caolan's async library \cite{caolan2017async} are other examples of reinventing control flow in eDSL.

Instead of reinventing the whole set of control flows for each DSL, a more general approach is implementing a minimal interface for control flows for each domain, while the syntax of other control flow operations are derived from the interface, shared between different domains. In Haskell and other functional programming language, monads are used as the generic interface of control flow \cite{wadler1990comprehending,wadler1992essence,jones1993composing}. Scala implementations of monads are provided by Scalaz \cite{kenji2017scalaz}, Cats \cite{typelevel2017cats} and Algebird \cite{twitter2016algebird}. A DSL author only have to implement \lstinline{bind} and \lstinline{point} functions in \lstinline{Monad} type class, and all the derived control flow operations like \lstinline{whileM} or \lstinline{ifM} are available. In addition, those monadic data type can be created and composed from \lstinline{do} or \lstinline{for} comprehension \cite{jones1998haskell,odersky2004scala}. For example, you can use the same \lstinline{scalaz.syntax} or \lstinline{for} comprehension to create random value generators \cite{nilsson2015scalacheck} and data-binding expressions \cite{yangbo2016binding}, as long as there are \lstinline{Monad} instances for data types \lstinline{org.scalacheck.Gen} and \lstinline{com.thoughtworks.binding.Binding} respectively.

An idea to avoid inconsistency between domain-specific control flow and ordinary control flow is converting ordinary control flow to domain-specific control flow at compiler time. For example, Scala Async provides a macro to generate asynchronous control flow \cite{haller2013sip}, allowing normal sequential code inside a \lstinline{scala.async} block to run asynchronously. This approach can be generalized to any monadic data types. ThoughtWorks Each \cite{yangbo2015each}, Monadless \cite{flavio2017monadless}, effectful \cite{crockett2013effectful} and !-notation in Idris \cite{brady2013idris} are compiler-time transformers to convert source code of ordinary control flow to monadic control flow. For example, with the help of ThoughtWorks Each, Binding.scala\cite{yangbo2016binding} can be used to create reactive HTML template from ordinary Scala control flow.

Another generic interface of control flow is continuation, which is known as the mother of all monads \cite{piponi2008mother}, where control flows in specific domain can be supported by specific answer types of continuations. Scala Continuations \cite{rompf2009implementing} and Stateless Future \cite{yangbo2014stateless} are two delimited continuation implementations in Scala. Both projects can convert ordinary control flow to continuation-passing style closure chains at compiler time. For example, Stateless Future Akka \cite{yangbo2014statelessfutureakka}, based on Stateless Future, provides a special answer type for akka actors. Unlike reinvented control flows in \lstinline{akka.actor.AbstractFSM}, users can create complex finite-state machines from simple ordinary control flows along with Stateless Future Akka's domain-specific operator \lstinline{nextMessage}.

All the previous approaches lack of the ability to collaborate with other DSLs. Each of the above DSLs can be exclusively enabled in a code block. Scala Continuations enables calls to \lstinline{@cps} method in \lstinline{reset} blocks, and ThoughtWorks Each enables the magic \lstinline{each} method \cite{yangbo2015each} for \lstinline{scalaz.Monad} in \lstinline{monadic} blocks. It was impossible to enable both DSL in one function.

This paper describes a novel approach to resolve the collaboration problem, and presents an implementation in Scala, the framework \textit{Dsl.scala}.

\textit{Dsl.scala} allows library authors to create special keywords for language features that were usually implemented by the compiler. Those library-defined keywords (LDKs) are adaptive to the enclosing DSL, as a library user can create one function that contains interleaved LDKs from different vendors, along with ordinary Scala control flows.

% TODO: link to other section.
\textit{Dsl.scala} also ships with some built-in LDKs, including:
\begin{itemize}
  \item The \lstinline{Shift} LDK for asynchronous programming, similar to the \lstinline[language=Python]{await} and \lstinline[language=Python]{async} keywords in C\#, Python and JavaScript.
  \item The \lstinline{Yield} LDK for generating lazy streams, similar to the \lstinline[language=Python]{yield} keyword in C\#, Python and JavaScript.
  \item The \lstinline{Fork} LDK for duplicating current thread, similar to the \lstinline{fork} system call in POSIX.
  \item The \lstinline{AutoClose} LDK to automatically close resources when exiting a scope, similar to the destructor feature in C++.
  \item The \lstinline{Monadic} LDK for creating Scalaz \cite{kenji2017scalaz} or Cats \cite{typelevel2017cats} monadic control flow, similar to the !-notation in Idris\cite{brady2013idris}.
\end{itemize}
 


%  Our approach is based on two assumptions:
% \begin{enumerate}
%   \item The return type is the specific domain of DSL.
%   \item A language feature should be adaptive to various domains along with the hosting language control flow.
% \end{enumerate}
% % By combining of the two assumptions, we build a DSL framework, and some examples of DSLs in various domains, including asynchronous or parallel programming, lazy stream generation, resource management.

% % an LDK in our framework can be adaptive to its contextual domain. A DSL user can create a single function that contains interleaved DSLs implemented by different vendors, along with ordinary Scala control flows.

% % We also provide some adapters to monad, which can be also used as a alternative syntactic sugar of monad comprehension.

% % DSL operators in our framework can be adaptive to its specific domain. A DSL user can create a single function that contains interleaved different DSLs implemented from different vendors, along with ordinary Scala control flows.

 
% % In functional programming, imperative control flow can be composed from monads \cite{wadler1990comprehending,wadler1992essence,jones1993composing}.
% % Along with monad transformers \cite{liang1995monad} and \lstinline{do} or \lstinline{for} comprehension \cite{jones1998haskell,odersky2004scala}, the ability of control flow

% % We show how a set of building blocks can be used to construct
% % programming language interpreters, and present implementations
% % of such building blocks capable of supporting many
% % commonly known features, including simple expressions,
% % three different function call mechanisms (call-by-name, call-by-value and lazy evaluation), references and assignment,
% % nondeterminism, first-class continuations, and program tracing.

\section{Using library-defined keywords}\label{Using library-defined keywords}

In this section, we will show some use cases from the perspective of the user of LDKs.

\subsection{Creating generators}\label{Creating generators}

Suppose Alice is creating an Xorshift pseudo-random number generator \cite{marsaglia2003xorshift}, and she wants to store the generated numbers in a lazily evaluated infinite stream. 

The usage of Alice's pseudo-random number generator is shown as below:

\begin{lstlisting}[caption={Using Alice's pseudo-random number generator},label={generatedNumbers}]
val generatedNumbers = aliceRandomGenerator(seed = 2463534242)
println(generatedNumbers(0))
println(generatedNumbers(1))
println(generatedNumbers(2))
\end{lstlisting}

Alice is a functional programming language developer. She wants to avoid mutable variables in the implementation. Unfortunately, a pseudo-random number generator usually has an internal state that are changed during generate new random number.

With the help of the built-in LDK \lstinline{Yield} from \textit{Dsl.scala}, Alice can implement the generator as a recursive function that produce the next random number in each iteration.

\begin{lstlisting}[caption={The implementation of Alice's pseudo-random number generator},label={aliceRandomGenerator}]
import com.thoughtworks.dsl.keywords.Yield
def aliceRandomGenerator(seed: Int): Stream[Int] = {
  val tmp1 = seed ^ (seed << 13)
  val tmp2 = tmp1 ^ (tmp1 >>> 17)
  val tmp3 = tmp2 ^ (tmp2 << 5)
  !Yield(tmp3)
  aliceRandomGenerator(tmp3)
}
\end{lstlisting}

\lstinline{aliceRandomGenerator} does not throw a \lstinline{StackOverflowError}, because the execution of \lstinline{aliceRandomGenerator} will be paused at the LDK \lstinline{Yield}, and it will be resumed when the caller is looking for the next number.

\lstinline{Yield} is an LDK to produce a value for a lazily evaluated \lstinline{Stream}, similar to the \lstinline[language=Python]{yield} keyword in C\#, JavaScript or Python. That is to say, \lstinline{Stream} is the domain where the domain-specific LDK \lstinline{Yield} can be used. More generally, all LDKs are domain-specific, where the word ``domain'' stands for the return type of the enclosing function.

\subsection{Creating generators with an additional return value}

In this use case, we will demonstrate how to add the logging feature to existing functions using the \lstinline{Yield} LDK.

Suppose Bob has a function to parse JSON text. The parser is fault-tolerant, since it returns the \lstinline{defaultValue} for invalid input  (Listing \ref{bobParser}).

\begin{lstlisting}[caption={The original implementation of Bob's parser},label={bobParser}]
import scala.util.parsing.json._
def bobParser(jsonContent: String, defaultValue: JSONType): JSONType = {
  JSON.parseRaw(jsonContent) match {
    case Some(json) =>
      callback(json)
    case None =>
      callback(defaultValue)
  }
}
\end{lstlisting}

Then, Bob wants to add the logging feature to his existing parser. He learnt from Alice's use case, and wonders if he can \lstinline{Yield} log messages to a \lstinline{Stream[String]} during parsing.

However, unlike Alice's case, Bob's parser should return both the parsed JSON objects and the collected logs. It's impossible in C\#'s \lstinline[language=Python]{yield}, because \lstinline[language=Python]{yield} does not work in a method that returns a JSON object.

Bob resolves the problem by creating a delimited continuation. The parsed JSON object is handled by a callback function instead of return value. Thus the return value is still a \lstinline{Stream}, allowing \lstinline{Yield}ing log messages (Listing \ref{bobLoggingParser}).

\begin{lstlisting}[caption={The implementation of Bob's logging parser},label={bobLoggingParser}]
import com.thoughtworks.dsl.Dsl.!!
def bobLoggingParser(jsonContent: String, defaultValue: JSONType): Stream[String] !! JSONType = { (callback: JSONType => Stream[String]) =>
  !Yield(s"I am going to parse the JSON text $jsonContent...")
  JSON.parseRaw(jsonContent) match {
    case Some(json) =>
      !Yield(s"Succeeded to parse $jsonContent")
      callback(json)
    case None =>
      !Yield(s"Failed to parse $jsonContent")
      callback(defaultValue)
  }
}
\end{lstlisting}

The return type of Bob's new parser is \lstinline{(Stream[String] !! JSONType)}, which is an alias to the delimited continuation \lstinline{((JSONType => Stream[String]) => Stream[String])}, indicating it produces both a \lstinline{scala.util.parsing.json.JSONType} and a \lstinline{Stream} of logs.

After Bob created the first version of delimited continuation, he then found that the closure can be simplified with the help of Scala's placeholder syntax (Listing \ref{bobLoggingParserUnderscore}).

\begin{lstlisting}[caption={The implementation of Bob's logging parser, the underscore placeholder version},label={bobLoggingParserUnderscore}]
def bobLoggingParserUnderscore(jsonContent: String, defaultValue: JSONType): Stream[String] !! JSONType = _ {
  !Yield(s"I am going to parse the JSON text $jsonContent...")
  JSON.parseRaw(jsonContent) match {
    case Some(json) =>
      !Yield(s"Succeeded to parse $jsonContent")
      json
    case None =>
      !Yield(s"Failed to parse $jsonContent")
      defaultValue
  }
}
\end{lstlisting}

Alternately, Bob can use the pre-defined function \lstinline{reset} instead of the underscore placeholder (Listing \ref{bobLoggingParserReset}).

\begin{lstlisting}[caption={The implementation of Bob's logging parser, the reset version},label={bobLoggingParserReset}]
def reset[R, A](a: => A): R !! A = _(a)

def bobLoggingParserReset(jsonContent: String, defaultValue: JSONType): Stream[String] !! JSONType = reset {
  !Yield(s"I am going to parse the JSON text $jsonContent...")
  JSON.parseRaw(jsonContent) match {
    case Some(json) =>
      !Yield(s"Succeeded to parse $jsonContent")
      json
    case None =>
      !Yield(s"Failed to parse $jsonContent")
      defaultValue
  }
}
\end{lstlisting}

Then, the user of Bob's parser calls \lstinline{bobLoggingParserReset} to handle both results (Listing \ref{usingBobLoggingParserDelay}):

\begin{enumerate}
  \item The JSON result in a callback function.
  \item The logs from return value.
\end{enumerate}

\begin{lstlisting}[caption={Using Bob's parser},label={usingBobLoggingParserDelay}]
val logs = bobLoggingParserReset("""{"key":"value"}""", JSONArray(Nil)) { json =>
  json should be(JSONObject(Map("key" -> "value")))
  Stream("done")
}
logs should be(
  Stream(
    "I am going to parse the JSON text {\"key\":\"value\"}...",
    "Succeeded to parse {\"key\":\"value\"}",
    "done"
  )
)
\end{lstlisting}

The use case of Bob's parser demonstrates how to enable additional LDKs into existing ordinary functions. Generally, an LDK user can introduce a new domain that supports more LDKs to an existing method with the two changes:

\begin{enumerate}
  \item Inserting a \lstinline{NewDomain!!} prefix to the return type (\lstinline{Stream[String]!!} in Bob's case).
  \item Inserting an \lstinline{reset} before the method block body.
\end{enumerate}

\subsection{Using multiple LDKs at once}\label{Using multiple LDKs at once}

In this use case, we will demonstrate how to use multiple library-defined keywords in one function.

Suppose Carol is creating a line splitter from a file. Carol wants to lazily read each line of a file to a \lstinline{Stream}, and automatically close the file handle after reading the last line, and finally return the total number of lines.

Carol will use the \lstinline{Yield} LDK to append a line to the \lstinline{Stream}, and the \lstinline{AutoClose} LDK to manage the life-cycle of the file handle.

\lstinline{Yield} LDK is only available in a function that returns \lstinline{Stream} or \lstinline{(Stream !! _)} as we already knows. Similarly, the \lstinline{AutoClose} LDK is only available in a function that returns \lstinline{(_ !! Throwable !! _)}. So, Carol makes her line splitter return \lstinline{(Stream[String] !! Throwable !! Int)} to enable both LDKs (Listing \ref{carolLineSplitter}).

\begin{lstlisting}[caption={Carol's line splitter},label={carolLineSplitter}]
import com.thoughtworks.dsl.Dsl.!!
import com.thoughtworks.dsl.keywords.AutoClose
import com.thoughtworks.dsl.keywords.Yield
import com.thoughtworks.dsl.keywords.Shift
import java.nio.file._, Files._

def carolLineSplitter(path: Path): Stream[String] !! Throwable !! Int = reset {
  val reader = !AutoClose(newBufferedReader(path))

  def loop(lineNumber: Int): Stream[String] !! Throwable !! Int = _ {
    reader.readLine() match {
      case null =>
        lineNumber
      case line =>
        !Yield(line)
        !Shift(loop(lineNumber + 1))
    }
  }

  !loop(0)
}
\end{lstlisting}

Note that \lstinline{(Stream[String] !! Throwable !! Int)} is a delimited continuation, Carol also needs \lstinline{Shift} LDK as the first-class delimited continuation operator\cite{danvy1990abstracting,asai2009typing} to create recursive calls.

The type \lstinline{(Stream[String] !! Throwable !! Int)} returned from \lstinline{carolLineSplitter} contains the following data:

\begin{itemize}
  \item A \lstinline{Stream} of each lines of the file, as the final return value.
  \item An optional \lstinline{Throwable} of the exception thrown during reading the file, which can be handled by a callback function.
  \item An \lstinline{Int} of the total number of lines in the file, which can be handled by another callback function.
\end{itemize}

The example code of using Carol's line splitter is shown in Listing \ref{usingCarolLineSplitter}.

\begin{lstlisting}[caption={Using Carol's line splitter},label={usingCarolLineSplitter}]
val allLines: Stream[String] = carolLineSplitter(Paths.get("multiline.txt")) { numberOfLines: Int =>
  println(s"There are ${numberOfLines} lines in multiline.txt")
  Function.const(Stream.empty)(_)
} { e: Throwable =>
  println("An error occurred during splitting multiline.txt")
}
\end{lstlisting}

In this use case, Carol created a function from three library-defined keywords.

\begin{enumerate}
  \item \lstinline{AutoClose} for resource management, similar to C++'s RAII feature.
  \item \lstinline{Yield} for lazily append values to a \lstinline{Stream}, similar to Python, C\# or ECMAScript's \lstinline[language=Python]{yield} keyword.
  \item \lstinline{Shift} for awaiting a value from a task, similar to Python, C\# or ECMAScript's \lstinline[language=Python]{await} keyword.
\end{enumerate}

What is interesting is that our library-defined keywords are more like first-class features than compiler-defined keywords. Despite the fact that Python 3.5, C\# and ECMAScript do not support automatic resource management, they also do not support using both \lstinline[language=Python]{yield} and \lstinline[language=Python]{await} in one function, even when \lstinline[language=Python]{yield} and \lstinline[language=Python]{await} are supported respectively, and Python 3.6 needs a special implementation of Asynchronous Generators \cite{pep525} to use both \lstinline[language=Python]{yield} and \lstinline[language=Python]{await}, while our library-defined keywords can collaborate with arbitrary other LDKs by composing extra domains on the return type.

\subsection{Fork / join in asynchronous programming}

When \lstinline{Stream} or other domains is unnecessary, \lstinline{TailRec[Unit] !! Throwable !! A} or the alias \lstinline{com.thoughtworks.dsl.task.Task} can be used as the default data type of task for asynchronous programming.

For example, Suppose Dave is creating an HTTP client. He can implement the HTTP protocol in the \lstinline{Task} domain shown in Listing \ref{daveHttpClient}.

\begin{lstlisting}[caption={Dave's HTTP client},label={daveHttpClient}]
import com.thoughtworks.dsl.task._
import com.thoughtworks.dsl.keywords._, Shift.implicitShift, AsynchronousIo._
import java.io._
import java.net._
import java.nio._, channels._

def readAll(channel: AsynchronousByteChannel, destination: ByteBuffer): Task[Unit] = _ {
  if (destination.remaining > 0) {
    val numberOfBytesRead: Int = !Read(channel, destination)
    numberOfBytesRead match {
      case -1 =>
      case _  => !readAll(channel, destination)
    }
  } else {
    throw new IOException("The response is too big to read.")
  }
}

def writeAll[Domain](channel: AsynchronousByteChannel, destination: ByteBuffer): Task[Unit] = _ {
  while (destination.remaining > 0) {
    !Write(channel, destination)
  }
}

def daveHttpClient(url: URL): Task[String] = _ {
  val socket = AsynchronousSocketChannel.open()
  try {
    val port = if (url.getPort == -1) 80 else url.getPort
    val address = new InetSocketAddress(url.getHost, port)
    !AsynchronousIo.Connect(socket, address)
    val request = ByteBuffer.wrap(s"GET ${url.getPath} HTTP/1.1\r\nHost:${url.getHost}\r\nConnection:Close\r\n\r\n".getBytes)
    !writeAll(socket, request)
    val response = ByteBuffer.allocate(100000)
    !readAll(socket, response)
    response.flip()
    io.Codec.UTF8.decoder.decode(response).toString
  } finally {
    socket.close()
  }
}
\end{lstlisting}

Dave's HTTP client is built from \lstinline{Connect}, \lstinline{Read} and \lstinline{Write} LDKs. Those are asynchronous Java NIO.2 IO operators defined in \lstinline{com.thoughtworks.dsl.keywords.AsynchronousIo}, working with \lstinline{com.thoughtworks.dsl.task.Task} domain.

The usage of \lstinline{Task} can be similar to previous examples in Section \ref{Using multiple LDKs at once}, but we also provide \lstinline{blockingAwait} and some other utilities under the implicit class \lstinline{com.thoughtworks.dsl.task.TaskOps} to ease the usage (Listing \ref{usingDaveHttpClient}).

\begin{lstlisting}[caption={Using Dave's http client},label={usingDaveHttpClient}]
val fileContent = daveHttpClient(new URL("http://ftp.debian.org/debian/")).blockingAwait
fileContent should startWith("HTTP/1.1 200 OK")
\end{lstlisting}


Another useful LDK for asynchronous programming is \lstinline{Fork}, which duplicate the current control flow, and the child control flows are executed in parallel, similar to the POSIX \lstinline{fork} system call.

Dave puts \lstinline{Fork} inside a \lstinline{join} block, which collects the result of each forked control flow (Listing \ref{usingDaveHttpClientInParallel}).

\begin{lstlisting}[caption={Using Dave's http client in parallel},label={usingDaveHttpClientInParallel}]
import com.thoughtworks.dsl.keywords.Fork
val Urls = Seq(
  new URL("http://ftp.debian.org/debian/README.CD-manufacture"),
  new URL("http://ftp.debian.org/debian/README")
)
def parallelTask: Task[Seq[String]] = Task.join {
  val url = !Fork(Urls)
  !daveHttpClient(url)
}

val Seq(fileContent0, fileContent1) = parallelTask.blockingAwait
fileContent0 should startWith("HTTP/1.1 200 OK")
fileContent1 should startWith("HTTP/1.1 200 OK")
\end{lstlisting}

The \lstinline{Task} implemented in \textit{Dsl.scala} is light-weight and faster. See section \ref{Benchmark} to see the performance benchmark between \lstinline{com.thoughtworks.dsl.task.Task}, \lstinline{scala.concurrent.Future}, \lstinline{scalaz.concurrent.Task} and \lstinline{monix.eval.Task}.

\subsection{Monadic programming}

Despite LDKs directly implemented in \textit{Dsl.scala}, we also provide some LDKs as adapters to monads and other type classes.

The built-in \lstinline{Monadic} LDK can be used as an adaptor to \lstinline{scalaz.Monad}, to create monadic code from imperative syntax, similar to the !-notation in Idris.

For example, suppose Erin is creating a program that counts lines of code under a directory. She uses the \lstinline{Monadic} LDK store the result in a \lstinline{Stream} of line count of each file (Listing \ref{erinMonadicCounter}).

\begin{lstlisting}[caption={Erin's line of code counter, the monadic version},label={erinMonadicCounter}]

import java.io.File
import com.thoughtworks.dsl.keywords.Monadic
import com.thoughtworks.dsl.domains.scalaz._
import scalaz.std.stream._
def erinMonadicCounter(file: File): Stream[Int] = Stream {
  if (file.isDirectory) {
    file.listFiles() match {
      case null =>
        // Unable to open `file`
        !Monadic(Stream.empty[Int])
      case children =>
        // Import this implicit conversion to omit the Monadic keyword
        import com.thoughtworks.dsl.keywords.Monadic.implicitMonadic
        val child: File = !children.toStream
        !erinMonadicCounter(child)
    }
  } else {
    scala.io.Source.fromFile(file).getLines.size
  }
}
\end{lstlisting}

The previous code requires a \lstinline{toStream} conversion on \lstinline{children}, because \lstinline{children}'s type \lstinline{Array[File]} does not fit the \lstinline{F} type parameter in \lstinline{scalaz.Monad.bind} \cite{kenji2017scalaz}.

There is a \lstinline{Each} LDK in \textit{Dsl.scala} to extract each element in a Scala collection, based on {CanBuildFrom} type class instead of monads. The \lstinline{Each} behavior is similar to \lstinline{Monadic}, except the collection type can vary.

Thus, Erin can extract each element from an \lstinline{Array} with the help of \lstinline{Each} LDK in Listing \ref{erinMixedCounter},
even when the enclosing domain is still a \lstinline{Stream}.

\begin{lstlisting}[caption={Erin's line of code counter, mixed \lstinline{Monad}-based and \lstinline{CanBuildFrom}-based LDKs},label={erinMixedCounter}]

import java.io.File
import com.thoughtworks.dsl.keywords.Monadic, Monadic.implicitMonadic
import com.thoughtworks.dsl.keywords.Each
import com.thoughtworks.dsl.domains.scalaz._
import scalaz.std.stream._
def erinMixedCounter(file: File): Stream[Int] = Stream {
  if (file.isDirectory) {
    file.listFiles() match {
      case null =>
        // Unable to open `file`
        !Stream.empty[Int]
      case children =>
        val child: File = !Each(children)
        !erinMixedCounter(child)
    }
  } else {
    scala.io.Source.fromFile(file).getLines.size
  }
}
\end{lstlisting}

As shown the \lstinline{erinMixedCounter}, Dsl.scala allows \lstinline{Each} and other non-monadic LDKs to work along with monads, which is impossible in Haskell's do-notation or Idris's !-notation.

However, Erin still wants to add one more feature to the LOC counter. Considering the line counter implemented in previous example may be failed for some files,
due to permission issue or other IO problem,
Erin wants to use an \lstinline{OptionT} monad transformer to mark those failed file as a \lstinline{None} (Listing \ref{erinTransformerCounter}).

\begin{lstlisting}[caption={Erin's line of code counter, using an \lstinline{OptionT} monad transformer},label={erinTransformerCounter}]
import scalaz._
import java.io.File
import com.thoughtworks.dsl.keywords.Monadic, Monadic.implicitMonadic
import com.thoughtworks.dsl.domains.scalaz._
import scalaz.std.stream._
def erinTransformerCounter(file: File): OptionT[Stream, Int] = OptionT.some {
  if (file.isDirectory) {
    file.listFiles() match {
      case null =>
        // Unable to open `file`
        !OptionT.none[Stream, Int]
      case children =>
        val child: File = !Stream(children: _*)
        !erinTransformerCounter(child)
    }
  } else {
    scala.io.Source.fromFile(file).getLines.size
  }
}
\end{lstlisting}

Note that our LDKs are adaptive to the domain it belongs to. Thus, instead of explicit lifting as \lstinline{!Monadic(OptionT.optionTMonadTrans.liftM(Stream(children: _*)))}, Erin can simply write \lstinline{!Stream(children: _*)}. This implicit lifting feature looks like Idris's effect monads \cite{brady2013programming}, though the mechanisms is different from \lstinline{implicit lift} in Idris.

\section{Creating library-defined keywords}\label{Creating library-defined keywords}

LDKs introduced in Section \ref{Using library-defined keywords} are optional libraries, activated by common compiler-time CPS-transform rules, which are implemented as a Scala compiler plug-in. In this section, we will present the implementation of some LDKs, and the compiler-time generated code for !-notations written by LDK users.

\textit{Dsl.scala} ships with a compiler plug-in that supports both nonadaptive LDKs and adapters LDKs. A nonadaptive LDK must belongs to in an exact domain, while an adaptive LDK works in various types of domains.

\subsection{Nonadaptive LDKs}

A Nonadaptive LDK is simply a delimited continuation, along with a syntactic \lstinline{unary_!} method for !-notation. For example, the \lstinline{Yield} LDK described at Section \ref{Creating generators} can be implemented as shown in Listing \ref{NonadaptiveYield}.

\begin{lstlisting}[caption={The \lstinline{Yield} LDK, the nonadaptive version},label={NonadaptiveYield}]
import com.thoughtworks.dsl.Dsl.shift
case class Yield[Element](element: Element) {

  @shift
  @compileTimeOnly("Calls to this method will be translated to cpsApply calls by the compiler plug-in")
  def unary_! : Value = ???

  @inline
  def cpsApply(handler: Unit => Stream[Element]): Stream[Element] = {
    new Stream.Cons(element, handler(()))
  }
}
\end{lstlisting}

Calls to \lstinline{unary_!} method will be translated to \lstinline{cpsApply} calls by our compiler plug-in. For example, \lstinline{aliceRandomGenerator} in Listing \ref{aliceRandomGenerator} will be translated to the code shown in Listing \ref{translatedAliceRandomGenerator} by our compiler plug-in:

\begin{lstlisting}[caption={The translated code for Alice's pseudo-random number generator},label={translatedAliceRandomGenerator}]
def aliceRandomGenerator(seed: Int): Stream[Int] = {
  val tmp1 = seed ^ (seed << 13)
  val tmp2 = tmp1 ^ (tmp1 >>> 17)
  val tmp3 = tmp2 ^ (tmp2 << 5)
  Yield(tmp3).cpsApply { _: Unit =>
    aliceRandomGenerator(tmp3)
  }
}
\end{lstlisting}

And Listing \ref{bobLoggingParser} or Listing \ref{bobLoggingParserUnderscore} will be translated to Listing \ref{translatedBobLoggingParser}:

\begin{lstlisting}[caption={The translated code for Bob's parser},label={translatedBobLoggingParser}]
import com.thoughtworks.dsl.Dsl.!!
def bobLoggingParser(jsonContent: String, defaultValue: JSONType): Stream[String] !! JSONType = { (callback: JSONType => Stream[String]) =>
  Yield(s"I am going to parse the JSON text $jsonContent...").cpsApply { _: Unit =>
    JSON.parseRaw(jsonContent) match {
      case Some(json) =>
        Yield(s"Succeeded to parse $jsonContent").cpsApply { _: Unit =>
          callback(json)
        }
      case None =>
        Yield(s"Failed to parse $jsonContent").cpsApply { _: Unit =>
          callback(defaultValue)
        }
    }
  }
}
\end{lstlisting}

Our compiler plug-in performs CPS-transform in a similar approach to Scala Continuations \cite{rompf2009implementing}, with some minor differences.

\begin{enumerate}
  
  \item Compiler-time instruction \lstinline{reset} is not necessary in our implementation, as the boundary of a delimited continuation is by default the enclosing function.
  
  \item All Return types is kept as is in our implementation, instead of hijacking on the \lstinline{@cps} type.
  \label{as-is}

  \item Our implementation only performs CPS-transform explicitly on the !-notation, instead of implicit conversion between \lstinline{@cps} type and ordinary type.

\end{enumerate}

Because of (\ref{as-is}), CPS-translated function produced by our compiler plug-in always has the same answer type as the return type, which is called the ``domain'' of a DSL. Even then, our approach still allows explicit answer type by using the underscore trick shown in Listing \ref{bobLoggingParserUnderscore}.

\subsection{Adaptive LDKs}

All \textit{Dsl.scala} built-in LDKs are adaptive, which can collaborate with other LDKs. For example, \lstinline{Yield} is adaptive, since it works not only in functions that return \lstinline{Stream}, but also \lstinline{(Stream !! _)}, \lstinline{(Stream !! _ !! _)}, etc. 

Those LDKs are adaptive because they all extends the \lstinline{trait Keyword}, which has a ad-hoc polymorphic \lstinline{cpsApply} method (Listing \ref{Keyword}).

\begin{lstlisting}[caption={The ad-hoc polymorphism in \lstinline{Keyword}},label={Keyword}]
trait Keyword[Self, Value] extends Any { this: Self =>

  @shift
  @compileTimeOnly("Calls to this method will be translated to cpsApply calls by the compiler plug-in")
  def unary_! : Value = ???

  def cpsApply[Domain](handler: Value => Domain)(implicit dsl: Dsl[Self, Domain, Value]): Domain = {
    dsl.interpret(this, handler)
  }

}
\end{lstlisting}

The functionality of \lstinline{cpsApply} is implemented in type class instances of \lstinline{Dsl} (Listing \ref{Dsl}).

\begin{lstlisting}[caption={The type class to interpret \lstinline{cpsApply}},label={Dsl}]
trait Dsl[Keyword, Domain, Value] {
  def interpret(keyword: Keyword, handler: Value => Domain): Domain
}
\end{lstlisting}

The adaptive version of \lstinline{Yield} LDK ships with a type class instance of \lstinline{Dsl[Yield[Element], Stream[Element], Unit]}, allowing the \lstinline{!Yield} notation in functions that return \lstinline{Stream[Element]}

\begin{lstlisting}[caption={The \lstinline{Yield} LDK, the adaptive version},label={Yield}]
case class Yield[Element](element: Element) extends Keyword[Yield[Element], Unit]

object Yield {
  implicit def yieldDsl[Element]: Dsl[Yield[Element], Stream[Element], Unit] =
    new Dsl[Yield[Element], Stream[Element], Unit] {
      def interpret(keyword: Yield[Element], mapper: Unit => Stream[Element]): Stream[Element] = {
        new Stream.Cons(keyword.element, mapper(()))
      }
    }
}
\end{lstlisting}

To make \lstinline{Yield} LDK available for another domain, just provide a \lstinline{Dsl} type class instance for other types.

Listing \ref{continuationDsl} shows a \lstinline{Dsl} that allows a LDK be available for \lstinline{Domain!!Value} as long as the LDK is available for \lstinline{Domain}.

\begin{lstlisting}[caption={The \lstinline{Yield} LDK, the adaptive version},label={continuationDsl}]
implicit def continuationDsl[Keyword, Domain, Value, KeywordValue](
  implicit restDsl: Dsl[Keyword, Domain, KeywordValue]
): Dsl[Keyword, Domain !! Value, KeywordValue] = {
  new Dsl[Keyword, Domain !! Value, KeywordValue] {
    def interpret(keyword: Keyword, handler: KeywordValue => Domain !! Value): Domain !! Value = {
      (continue: Value => Domain) =>
        restDsl.interpret(keyword, { a =>
          handler(a)(continue)
        })
    }
  }
}
\end{lstlisting}

Therefore, the \lstinline{Yield} LDK can be used in \lstinline{(Stream[String] !! JsonType)} domain as shown in Listing \ref{bobLoggingParserReset}, because the type class \lstinline{Dsl[Yield[String], Stream !! JsonType, Unit]} can be implicitly resolved as \lstinline{continuationDsl(yieldDsl)}.

\section{Benchmark}\label{Benchmark}


\section{Conclusion}\label{conclusion}


\clearpage
% Appendix
\appendix

\printglossary

\begin{acks}
% TODO:
\end{acks}

% Bibliography
\bibliography{bibliography}
